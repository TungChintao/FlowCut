# FlowCut for Qwen2VL

Here, we provide the implementation details of FlowCut for Qwen2-VL, which are also applicable to Qwen2.5-VL. Qwen2 VL already employs PatchMerger for visual token compression. As a result, the performance gain from FlowCut is less striking compared to LLaVA. 

---

## üöÄ Quick Start

```python
from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor
from FlowCut_Qwen import flowcut

model_path = "qwen/qwen2-vl-7b"
model = Qwen2VLForConditionalGeneration.from_pretrained(model_path, device_map='cuda', torch_dtype=torch.float16).eval()
processor = Qwen2VLProcessor.from_pretrained(model_path, max_pixels=1280*28*28)

model = flowcut(model, target_num=64)
```

‚ö†Ô∏è Due to the variable length of visual tokens generated by Qwen2VL‚Äôs naive dynamic resolution, FlowCut **currently only supports `batch_size=1`**. We support both **FlashAttention-2** and **Eager Attention**.

---

## Results
| Retain Ratio | GQA | MMB | MMB-CN | MME  | POPE | SQA | TextVQA | Avg. |
| :----------: | :--: | :---: | :------: | :--: | :-------: | :----: | :-------: | :-------: |
| 100%         | 61.9 | 79.9 |  79.5  | 2338 | 87.2 | 85.1 |  82.2   | 100%  |
| 33.3%      | 60.5 | 79.2 |  78.2  | 2335 | 86.0 | 84.0 |  81.1   | 98.7% |
| 22.2%      | 59.2 | 77.8 |  76.9  | 2310 | 84.6 | 80.5 |  78.3   | 96.5% |
| 11.1% | 56.4 | 72.6 | 72.5 | 2252 | 81.8 | 78.2 | 68.9 | 91.3% |

